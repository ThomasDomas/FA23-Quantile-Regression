# Analysis

In this analysis we aim to show that QR can achieve similar--- if not better--- performance to OLS across various metrics. OLS and QR are very different modeling techniques, and, as such, it is difficult to compare them. However, given that OLS estimates the mean value of the response variable for a given input vector and QR estimates the nth quantile of the response variable for a given input vector, the 50th quantile QR (QR50)--- which corresponds to the median--- can be used as a comparison to OLS as both the median and mean are measures of centrality. The limitation of this analysis is that the data set does not meet the assumptions of OLS. Specifically, the data is heavily skewed and the conditional distributions are also skewed, meaning median of the conditional distribution is a better proxy for the centrality of the distribution. The power of QR is that it is able to produce similar results to OLS regression without having to meet the strict assumptions of OLS. Regardless of the fact the OLS regressions are statistically invalid, it is still going to minimizee the square deviations of the residuals from the regression curve, which often results much higher scores across popular metrics than other modeling techniques, and will thus serve as a proper benchmark to test the mettle of QR in a data set that is beyond the capabilities of OLS regression.

```{r, echo=FALSE, include=FALSE}
library(quantreg)
library(Metrics)
require(gridExtra)
library(ggplot2)
#install.packages("jtools")
library(jtools)
#install.packages("huxtable")
library(huxtable)
```

## Visualization

```{r, 'Getting Data housing', echo=FALSE, warning=FALSE}
df <- read.csv("TrainData.csv") |>
  na.omit()

#summary(df)
```

### Visualizing the Data

There are many different kinds of predictor variables in this data set. For instance, there are continuous variables such as GrLivArea, counting variables such as YearBuilt, and categorical variables such as HouseStyle. In all of these cases, we can see that the data is not normally distributed, including the response variable, SalePrice. The relationships between the variables and their distributions are illustrated in a joint plot below.

using [@gridExtra] and [@ggplot2]

```{r 'Visualizing data', warning=FALSE}
suppressWarnings({

p1 <- df |> ggplot(aes(x = GrLivArea)) + geom_histogram(binwidth = 100) + theme_bw() + theme(axis.text.y = element_blank(), axis.text.x = element_text(angle = 90), axis.ticks.y = element_blank()) + ylab(NULL) + xlab("House Area (sq. ft.)") + scale_x_continuous(position = "top")

p2 <- df |> ggplot(aes(x = YearBuilt)) + geom_histogram(binwidth = 5) + theme_bw() + theme(axis.text.y = element_blank(), axis.text.x = element_text(angle = 90), axis.ticks.y = element_blank()) + ylab(NULL) + xlab("Year Built") + scale_x_continuous(position = "top")

p3 <- df |> ggplot(aes(x = HouseStyle)) + geom_histogram(stat="count") + theme_bw() + theme(axis.text.y = element_blank(), axis.text.x = element_text(angle = 90), axis.ticks.y = element_blank()) + ylab(NULL) + xlab("House Style") + scale_x_discrete(position = "top")

p4 <- ggplot() + theme_minimal()

p5 <- df |> ggplot(aes(x = GrLivArea, y = SalePrice)) + geom_point() + theme_bw() + theme(axis.text = element_blank(), axis.ticks = element_blank()) + ylab(NULL) + xlab(NULL)

p6 <- df |> ggplot(aes(x = YearBuilt, y = SalePrice)) + geom_point() + theme_bw() + theme(axis.text = element_blank(), axis.ticks = element_blank()) + ylab(NULL) + xlab(NULL)

p7 <- df |> ggplot(aes(x = HouseStyle, y = SalePrice)) + geom_point() + theme_bw() + theme(axis.text = element_blank(), axis.ticks = element_blank()) + ylab(NULL) + xlab(NULL)

p8 <- df |> ggplot(aes(x = SalePrice)) + geom_histogram(binwidth = 10000) + theme_bw() + ylab(NULL) + xlab("Sale Price ($)") + coord_flip() + scale_x_continuous(position = "top") + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, nrow = 2)

})
```

Thus, the data fails to meet the assumptions of OLS, requiring the usage of a more flexible model like QR.

### Visualizing quantile regression vs OLS

#### Difference between the 50th quantile and mean.

```{r, 'Visualizing housing', warning=FALSE}

df |> ggplot(aes(y = SalePrice, x = LotArea)) +
  geom_point(size = 0.9) +
  geom_smooth(method = lm, se = F, color = "black") +
  geom_text(aes(y = 400000, x = 150000, label = "OLS"), color="black") + 
  geom_quantile(quantiles=0.5, color="red") + 
  geom_text(aes(y = 470000, x = 90000, label = "50th quantile"), color="red") + 
  ylab("Sale price ($)") +
  xlab("Lot area (Square feet)") +
  theme_bw()
```

As demonstrated in the graph, The slope of OLS is slightly lower than the slope of 50th quantile. That is probably due to the 3 points which look like outliers on the far right below the OLS slope. They heavily affect the value of the OLS but the Quantile regression is unaffected by it due to the mathematical property of the median.

#### Viewing the different quantiles of Quantile regression.

```{r, 'Visualizing housing cont', warning=FALSE}
df |> ggplot(aes(y = SalePrice, x = GrLivArea)) +
  geom_point(size = 0.9) +
  stat_smooth(method = lm, color = "black") +
  geom_text(aes(x = 4150, y = 500000, label = "OLS"), color="black") + 
  geom_quantile(quantiles=0.25, color="red") + 
  geom_text(aes(x = 4000, y = 270000, label = "25th quantile"), color="red") + 
  geom_quantile(quantiles=0.5, color="blue") + 
  geom_text(aes(x = 4150, y = 400000, label = "50th"), color="blue") + 
  geom_quantile(quantiles=0.75, color="green") + 
  geom_text(aes(x = 4000, y = 600000, label = "75th quantile"), color="green") + 
  xlab("Sale price ($)") +
  ylab("Above ground area (Square feet)") +
  theme_bw()
```

In this graph, when plotting sales price against ground living area, Quantile regression 50th quantile and OLS look very similar in slope and y-intercept. However, when viewing the greater picture, Quantile regression actually offers a special regression line calculation for every partition of data as determined by tau value. So for the 75th quantile line, this slope would be the best to describe the prices for houses with ground living area larger than 75% of the data. While the 25th quantile line would be the best at describing houses with ground living areas less than 75% of the dataset.

## Model creation

### QR model

using [@quantreg]

```{r 'QR model creation', warning=FALSE}
qr50 = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=0.5)
qr50_summary = summary(qr50)
```

```{r, results='hide', echo=FALSE, message=FALSE, warning=FALSE}
#Generate all QR models 
taus <- seq(from=0, to=1, by=.01)
qrs = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=taus)
taus <- seq(from=0, to=1, by=.1)
qrs = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=taus)
plot_summs(qr50)
```

```{r, warning=FALSE}
num_of_rows <- nrow(qrs$coefficients)
par(mfrow = c(2, 2))
plot.new()
mtext("Beta change per quantile level", side = 3, line = - 2, outer = TRUE)
plot(qrs$coefficients[1, ], xlab="Quantiles", ylab="Y-Intercepts")
plot(qrs$coefficients[2, ], xlab="Quantiles", ylab="Lot-Area")
plot(qrs$coefficients[3, ], xlab="Quantiles", ylab="TotRmsAbvGrd")
plot(qrs$coefficients[4, ], xlab="Quantiles", ylab="LotShape-IR2")
mtext("Beta change per quantile level", side = 3, line = - 2, outer = TRUE)
plot(qrs$coefficients[5, ], xlab="Quantiles", ylab="LotShape-IR3")
plot(qrs$coefficients[6, ], xlab="Quantiles", ylab="LotShape-Reg")
plot(qrs$coefficients[7, ], xlab="Quantiles", ylab="Foundation-CBlock")
plot(qrs$coefficients[8, ], xlab="Quantiles", ylab="Foundation-PConc")
mtext("Beta change per quantile level", side = 3, line = - 2, outer = TRUE)
plot(qrs$coefficients[9, ], xlab="Quantiles", ylab="Foundation-Slab")
plot(qrs$coefficients[10, ], xlab="Quantiles", ylab="Foundation-Stone")
plot(qrs$coefficients[11, ], xlab="Quantiles", ylab="Foundation-Wood")

```

## Interpretation of betas

```{r}
options(scipen=5)
qr10 = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=.1)
qr30 = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=.3)
qr50 = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=.5)
qr70 = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=.7)
qr90 = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=.9)
plot_summs(qr10, qr30, qr50, qr70, qr90, se="iid", ci=.95) #, qr50, qr70, qr90)
export_summs(qr10, qr30, qr50, qr70, qr90, se="iid")
```
                   ──────────────────────────────────────────────────────────────────────────────────────────────────────────
                                                      Model 1         Model 2         Model 3         Model 4         Model 5     
                                                 ─────────────────────────────────────────────────────────────────────────────────
                          (Intercept)               44918.14 ***    43104.15 ***    36326.81 ***    22388.39 ***    12828.55      
                                                    (9958.59)       (4786.61)       (5436.58)       (5905.57)       (7945.83)     
                          GrLivArea                    59.78 ***       86.99 ***       96.67 ***      103.31 ***      122.36 ***  
                                                       (6.22)          (2.99)          (3.39)          (3.69)          (4.96)     
                          LotArea                       0.51 **         1.06 ***        1.00 ***        1.85 ***        3.20 ***  
                                                       (0.20)          (0.09)          (0.11)          (0.12)          (0.16)     
                          TotRmsAbvGrd              -3760.05 *      -6971.12 ***    -6476.18 ***    -4824.76 ***    -5722.68 ***  
                                                    (1913.59)        (919.77)       (1044.67)       (1134.78)       (1526.83)     
                          as.factor(LotShape)IR2     4840.55        -5886.44        -5084.13          643.09        -7348.43      
                                                   (11118.13)       (5343.95)       (6069.59)       (6593.19)       (8871.02)     
                          as.factor(LotShape)IR3    -5205.53       -35251.72 ***   -21074.81       -18689.73       -33498.32      
                                                   (21961.72)      (10555.93)      (11989.30)      (13023.57)      (17522.97)     
                          as.factor(LotShape)Reg   -20808.19 ***   -14850.39 ***   -11065.07 ***    -9142.87 ***    -5890.43      
                                                    (3849.01)       (1850.03)       (2101.24)       (2282.51)       (3071.08)     
                          as.factor(Foundation)C    20043.99 **     18347.28 ***    21252.41 ***    21512.77 ***    14295.61 **   
                          Block                                                                                                   
                                                    (6163.21)       (2962.36)       (3364.61)       (3654.86)       (4917.55)     
                          as.factor(Foundation)P    50167.36 ***    50155.98 ***    53311.16 ***    61323.28 ***    85822.78 ***  
                          Conc                                                                                                    
                                                    (6223.23)       (2991.20)       (3397.38)       (3690.45)       (4965.44)     
                          as.factor(Foundation)S     -264.83       -11272.18       -16867.21 *     -20032.89 *     -13083.83      
                          lab                                                                                                     
                                                   (14627.68)       (7030.81)       (7985.52)       (8674.39)      (11671.23)     
                          as.factor(Foundation)S   -20399.97        -5889.52        14561.55        16429.67        -2166.19      
                          tone                                                                                                    
                                                   (27696.30)      (13312.26)      (15119.92)      (16424.25)      (22098.52)     
                          as.factor(Foundation)W    28298.39         1356.26        -2008.82       -14804.37       -53100.42      
                          ood                                                                                                     
                                                   (38945.74)      (18719.32)      (21261.19)      (23095.30)      (31074.31)     
                                                 ─────────────────────────────────────────────────────────────────────────────────
                          N                          1460            1460            1460            1460            1460         
                          tau                           0.10            0.30            0.50            0.70            0.90      
                          R1                            0.29            0.38            0.44            0.48            0.54      
                          AIC                       35721.34        35194.94        35180.97        35468.82        36275.49      
                          BIC                       35784.78        35258.37        35244.41        35532.26        36338.92      
                        ──────────────────────────────────────────────────────────────────────────────────────────────────────────
                          *** p < 0.001; ** p < 0.01; * p < 0.05.                                                                 



Of all the house shapes, irregular house shape 1, IR1, seems to have the most least negative impact. Except near the highest quantiles, the impact of IR2 on the price of houses was about 5000 dollars less than that of IR1. Furthermore, there was very little difference between IR3 and IR1. IR3 only made a difference near the lower quantiles where it added between 40-60k in price.

The foundation variables also had some interesting behavior. Stone had a parabolic shape across the quantiles. Relative to brick, it's effect on price was very high at the lower quantiles, hit it's lowest point at the 60th quantile, and then began to increase after the 60th quantile. Furthermore, relative to brick, wood foundations had an almost stepwise pattern. About every 20 quantiles, the price would jump upward and then decrease. This is perhaps due to the widely varying conditions that a wood foundation can come in. Lastly, relative to brick, concrete slab was the only beta foundation that consistently increased across all of the quantiles. It starts off at 40k near the lower end of the quantiles and increases to 120k near the upper end of the quantiles.

Although lot shape and foundation had strange patterns, lot area and total rms above ground had a relatively expected pattern. They both increased positively and in a linear pattern across all the quantiles. Lot area started at around a 40 dollars at the lower quantiles and maxed out at around 120 at the upper quantiles. Furthermore RMS started at a dollar at the lower ends and maxed out at about 3 near the 90th quantile.

### OLS model

```{r 'OLS model creation', warning=FALSE}

ols = lm(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation))
ols_summary = summary(ols)
ols_summary
```

## Model evaluation

### Mean absolute error

using [@Metrics]

```{r 'Mean absolute error', warning=FALSE}
olsMae = mae(predict(ols), df$SalePrice)
olsMae
Qr50Mae = mae(predict(qr50), df$SalePrice)
Qr50Mae
```

OLS MAE value: `r format(round(olsMae, digits=2), scientific=F)`. And QR 50th MAE value: `r format(round(Qr50Mae, digits=2), scientific=F)`. QR for 50th quantile has a lower MAE therefore it is has more accurate predictions but they are almost the same.

```{r 'MAE for different quantiles', warning=FALSE}
fullDataLength = length(df$SalePrice)
fullDataLength
count10per = fullDataLength / 10
count10per
sorted_df_desc <- df[order(-df$SalePrice),]
Q90SalePrice <- sorted_df_desc[0:count10per, ] # data greater than 90% of data
length(Q90SalePrice$SalePrice)

qr90_m = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=0.90)

ols_q90_predictions <- predict(ols, newdata=Q90SalePrice)
ols_q90_mae <- mae(ols_q90_predictions, Q90SalePrice$SalePrice)
ols_q90_mae

qr90_q90_predictions <- predict(qr90_m, newdata=Q90SalePrice)
qr90_q90_mae <- mae(qr90_q90_predictions, Q90SalePrice$SalePrice)
qr90_q90_mae

###########
sorted_df_asc <- df[order(df$SalePrice),]
length(sorted_df_asc$SalePrice)
Q10SalePrice <- sorted_df_asc[0:count10per, ] # data lower than 90% of data
length(Q10SalePrice$SalePrice)

qr10_m = rq(data=df, SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation), tau=0.10)

ols_q10_predictions <- predict(ols, newdata=Q10SalePrice)
ols_q10_mae <- mae(ols_q10_predictions, Q10SalePrice$SalePrice)
ols_q10_mae

qr10_q10_predictions <- predict(qr10_m, newdata=Q10SalePrice)
qr10_q10_mae <- mae(qr10_q10_predictions, Q10SalePrice$SalePrice)
qr10_q10_mae

```

When comparing Quantile regression for tau = 0.90 with OLS while predicting the top 10% of data when sorted by sales amount. The OLS model had MAE value of `r format(round(ols_q90_mae, digits=2), scientific=F)`, while QR had MAE value of `r format(round(qr90_q90_mae, digits=2), scientific=F)`. And when comparing Quantile regression for tau = 0.10 with OLS while predicting the bottom 10% of data when sorted by sales amount. The OLS model had MAE value of `r format(round(ols_q10_mae, digits=2), scientific=F)`, while QR had MAE value of `r format(round(qr10_q10_mae, digits=2), scientific=F)`. So QR has better MAE than OLS when predicting data that is far off the mean. That is a big advantage of QR as it has the flexibility to provide models for a specific set of the data.

### Root mean squared error

using [@Metrics]

```{r 'Root mean squared error', warning=FALSE}
olsRmse = rmse(predict(ols), df$SalePrice)
olsRmse
Qr50Rmse = rmse(predict(qr50), df$SalePrice)
Qr50Rmse
```

OLS RMSE value: `r format(round(olsRmse, digits=2), scientific=F)`. And QR 50th RMSE value: `r format(round(Qr50Rmse, digits=2), scientific=F)`. Since OLS' goal is to minimize RMSE, as expected it has a better (lower) value. But QR has a very similar value which shows how well QR model can keep up even if it is not focusing on optimizing RMSE.

```{r 'Root mean squared error for specific quantiles', warning=FALSE}
ols_q90_rmse <- rmse(ols_q90_predictions, Q90SalePrice$SalePrice)
ols_q90_rmse

qr90_q90_rmse <- rmse(qr90_q90_predictions, Q90SalePrice$SalePrice)
qr90_q90_rmse

ols_q10_rmse <- rmse(ols_q10_predictions, Q10SalePrice$SalePrice)
ols_q10_rmse

qr10_q10_rmse <- rmse(qr10_q10_predictions, Q10SalePrice$SalePrice)
qr10_q10_rmse
```

When comparing Quantile regression for tau = 0.90 with OLS while predicting the top 10% of data when sorted by sales amount. The OLS model had RMSE value of `r format(round(ols_q90_rmse, digits=2), scientific=F)`, while qr90_QR had RMSE value of `r format(round(qr90_q90_rmse, digits=2), scientific=F)`. And when comparing Quantile regression for tau = 0.10 with OLS while predicting the bottom 10% of data when sorted by sales amount. The OLS model had RMSE value of `r format(round(ols_q10_rmse, digits=2), scientific=F)`, while QR had RMSE value of `r format(round(qr10_q10_rmse, digits=2), scientific=F)`. So QR also has better RMSE than OLS when predicting data that is far off the mean, even though OLS is supposed to minimize RMSE value.

### Variance of error

```{r 'Variance of error', warning=FALSE}
ols_summary$df[2]
qr50_summary$rdf
```

The variance of error for OLS: `r format(ols_summary$df[2], scientific=F)`.

The variance of error for QR 50th: `r format(qr50_summary$rdf, scientific=F)`.

Both have the same variance of error.

### Min/max error

```{r 'Min/Max Error', warning=FALSE}
ols_r <- ols_summary$residuals
# Min OLS error
format(round(min(ols_r), digits=0), scientific=F)
# Absolute min OLS error
format(round(min(abs(ols_r)), digits=0), scientific=F)
# Max OLS error
format(round(max(ols_r), digits=0), scientific=F)
# Absolute max OLS error
format(round(max(abs(ols_r)), digits=0), scientific=F)
# Avg QR OLS error
format(round(mean(abs(ols_r)), digits=0), scientific=F)

# Min QR 50th error
qr50_r <- qr50_summary$residuals
format(round(min(qr50_r), digits=0), scientific=F)
# Absolute min QR 50th error
format(round(min(abs(qr50_r)), digits=0), scientific=F)
# Max QR 50th error
format(round(max(qr50_r), digits=0), scientific=F)
# Absolute max QR 50th error
format(round(max(abs(qr50_r)), digits=0), scientific=F)
# Avg QR 50th error
format(round(mean(abs(qr50_r)), digits=0), scientific=F)
```

#### OLS

Min OLS error: `r format(round(min(ols_r), digits=0), scientific=F)`.

Absolute min OLS error: `r format(round(min(abs(ols_r)), digits=0), scientific=F)`.

Max OLS error: `r format(round(max(ols_r), digits=0), scientific=F)`.

Absolute max OLS error: `r format(round(max(abs(ols_r)), digits=0), scientific=F)`.

mean OLS error: `r format(round(mean(abs(ols_r)), digits=0), scientific=F)`.

#### QR

##### QR tau = 0.5

Min QR 50th error: `r format(round(min(qr50_r), digits=0), scientific=F)`.

Absolute min QR 50th error: `r format(round(min(abs(qr50_r)), digits=0), scientific=F)`.

Max QR 50th error: `r format(round(max(qr50_r), digits=0), scientific=F)`.

Absolute max QR 50th error: `r format(round(max(abs(qr50_r)), digits=0), scientific=F)`.

mean QR 50th error: `r format(round(mean(abs(qr50_r)), digits=0), scientific=F)`.

##### QR tau = 0.9

```{r 'Min/Max Error for tau = 0.9', warning=FALSE}
ols_q90_r <- Q90SalePrice$SalePrice - ols_q90_predictions
# Avg OLS error
ols_q90_r_abs_avg <- format(round(mean(abs(ols_q90_r)), digits=0), scientific=F)
ols_q90_r_abs_avg
# Min OLS error
ols_q90_r_min <- format(round(min(ols_q90_r), digits=0), scientific=F)
ols_q90_r_min
# Absolute min OLS error
ols_q90_r_min_abs <- format(round(min(abs(ols_q90_r)), digits=0), scientific=F)
ols_q90_r_min_abs
# Max OLS error
ols_q90_r_max <- format(round(max(ols_q90_r), digits=0), scientific=F)
ols_q90_r_max
# Absolute max OLS error
ols_q90_r_max_abs <- format(round(max(abs(ols_q90_r)), digits=0), scientific=F)
ols_q90_r_max_abs

### QR for tau = 0.9
qr90_q90_r <- Q90SalePrice$SalePrice - qr90_q90_predictions
# Avg QR 90th error
qr90_q90_r_abs_avg <- format(round(mean(abs(qr90_q90_r)), digits=0), scientific=F)
qr90_q90_r_abs_avg
# Min QR 90th error
qr90_q90_r_min <- format(round(min(qr90_q90_r), digits=0), scientific=F)
qr90_q90_r_min
# Absolute min QR 90th error
qr90_q90_r_min_abs <- format(round(min(abs(qr90_q90_r)), digits=0), scientific=F)
qr90_q90_r_min_abs
# Max QR 90th error
qr90_q90_r_max <- format(round(max(qr90_q90_r), digits=0), scientific=F)
qr90_q90_r_max
# Absolute max QR 90th error
qr90_q90_r_max_abs <- format(round(max(abs(qr90_q90_r)), digits=0), scientific=F)
qr90_q90_r_max_abs

ols_q90_r_max_abs < qr90_q90_r_max_abs
```

When predicting the 90th quantile:

The average error for OLS predictions is: `r ols_q90_r_abs_avg`, while the average error for QR with tau = 0.9 predictions is: `r qr90_q90_r_abs_avg`.

The minimum error for OLS predictions is: `r ols_q90_r_min`, while the minimum error for QR with tau = 0.9 predictions is: `r qr90_q90_r_min`.

The absolute minimum error for OLS predictions is: `r ols_q90_r_min_abs`, while the absolute minimum error for QR with tau = 0.9 predictions is: `r qr90_q90_r_min_abs`.

The maximum error for OLS predictions is: `r ols_q90_r_max`, while the maximum error for QR with tau = 0.9 predictions is: `r qr90_q90_r_max`.

The absolute maximum error for OLS predictions is: `r ols_q90_r_max_abs`, while the absolute maximum error for QR with tau = 0.9 predictions is: `r qr90_q90_r_max_abs`.

##### QR tau = 0.1

```{r 'Min/Max Error for tau = 0.1', warning=FALSE}
ols_q10_r <- ols_q10_predictions - Q10SalePrice$SalePrice
# Avg OLS error
ols_q10_r_abs_avg <- format(round(mean(abs(ols_q10_r)), digits=0), scientific=F)
ols_q10_r_abs_avg
# Min OLS error
ols_q10_r_min <- format(round(min(ols_q10_r), digits=0), scientific=F)
ols_q10_r_min
# Absolute min OLS error
ols_q10_r_min_abs <- format(round(min(abs(ols_q10_r)), digits=0), scientific=F)
ols_q10_r_min_abs
# Max OLS error
ols_q10_r_max <- format(round(max(ols_q10_r), digits=0), scientific=F)
ols_q10_r_max
# Absolute max OLS error
ols_q10_r_max_abs <- format(round(max(abs(ols_q10_r)), digits=0), scientific=F)
ols_q10_r_max_abs

length(Q10SalePrice$SalePrice)
length(df$SalePrice)
qr10_q10_r <- resid(qr10_m, newdata=Q10SalePrice)
# Avg QR 10th error
qr10_q10_r_abs_avg <- format(round(mean(abs(qr10_q10_r)), digits=0), scientific=F)
qr10_q10_r_abs_avg
# Min QR 10th error
qr10_q10_r_min <- format(round(min(qr10_q10_r), digits=0), scientific=F)
qr10_q10_r_min
# Absolute min QR 10th error
qr10_q10_r_min_abs <- format(round(min(abs(qr10_q10_r)), digits=0), scientific=F)
qr10_q10_r_min_abs
# Max QR 10th error
qr10_q10_r_max <- format(round(max(qr10_q10_r), digits=0), scientific=F)
qr10_q10_r_max
# Absolute max QR 10th error
qr10_q10_r_max_abs <- format(round(max(abs(qr10_q10_r)), digits=0), scientific=F)
qr10_q10_r_max_abs
```

When predicting the 10th quantile:

The average error for OLS predictions is: `r ols_q10_r_abs_avg`, while the average error for QR with tau = 0.1 predictions is: `r qr10_q10_r_abs_avg`.

The minimum error for OLS predictions is: `r ols_q10_r_min`, while the minimum error for QR with tau = 0.1 predictions is: `r qr10_q10_r_min`.

The absolute minimum error for OLS predictions is: `r ols_q10_r_min_abs`, while the absolute minimum error for QR with tau = 0.1 predictions is: `r qr10_q10_r_min_abs`.

The maximum error for OLS predictions is: `r ols_q10_r_max`, while the maximum error for QR with tau = 0.1 predictions is: `r qr10_q10_r_max`.

The absolute maximum error for OLS predictions is: `r ols_q10_r_max_abs`, while the absolute maximum error for QR with tau = 0.1 predictions is: `r qr10_q10_r_max_abs`.

## Tests for significant variables

### Common function to help in calculating p-values
```{r, warning=FALSE}
getQrModel <- function(data1, tau1, equation) {
  rq(data=data1, equation, tau=tau1)
}

getPvalue <- function(model1, model2) {
  anova(model1, model2)["table"]$table["pvalue"]
}
```

```{r, warnings=FALSE}
eq_full <- SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape) + as.factor(Foundation)
eq_no_foundation <- SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(LotShape)
eq_no_lotshape <- SalePrice ~ GrLivArea + LotArea + TotRmsAbvGrd + as.factor(Foundation)


qr15 <- getQrModel(df, 0.15, eq_full)
qr15_no_f <- getQrModel(df, 0.15, eq_no_foundation)
qr15_no_lot <- getQrModel(df, 0.15, eq_no_lotshape)

foundation_15_p <- getPvalue(qr15, qr15_no_f)
foundation_15_p
lotshape_15_p <- getPvalue(qr15, qr15_no_lot)
lotshape_15_p


qr25 <- getQrModel(df, 0.25, eq_full)
qr25_no_f <- getQrModel(df, 0.25, eq_no_foundation)
qr25_no_lot <- getQrModel(df, 0.25, eq_no_lotshape)

foundation_25_p <- getPvalue(qr25, qr25_no_f)
foundation_25_p
lotshape_25_p <- getPvalue(qr25, qr25_no_lot)
lotshape_25_p


qr50 <- getQrModel(df, 0.50, eq_full)
qr50_no_f <- getQrModel(df, 0.50, eq_no_foundation)
qr50_no_lot <- getQrModel(df, 0.50, eq_no_lotshape)

foundation_50_p <- getPvalue(qr50, qr50_no_f)
foundation_50_p
lotshape_50_p <- getPvalue(qr50, qr50_no_lot)
lotshape_50_p


qr80 <- getQrModel(df, 0.80, eq_full)
qr80_no_f <- getQrModel(df, 0.80, eq_no_foundation)
qr80_no_lot <- getQrModel(df, 0.80, eq_no_lotshape)

foundation_80_p <- getPvalue(qr80, qr80_no_f)
foundation_80_p
lotshape_80_p <- getPvalue(qr80, qr80_no_lot)
lotshape_80_p


qr95 <- getQrModel(df, 0.95, eq_full)
qr95_no_f <- getQrModel(df, 0.95, eq_no_foundation)
qr95_no_lot <- getQrModel(df, 0.95, eq_no_lotshape)

foundation_95_p <- getPvalue(qr95, qr95_no_f)
foundation_95_p
lotshape_95_p <- getPvalue(qr95, qr95_no_lot)
lotshape_95_p
## q75, q10 and q90 gives singularity errors
```

Alpha=0.01

|Quantile   |foundation p-value   | significant?    | lot shape p-value   | significant?    |
|----------:|--------------------:|----------------:|--------------------:|----------------:|
|0.15       |`r foundation_15_p`  |`r foundation_15_p<0.01`|`r lotshape_15_p`  |`r lotshape_15_p<0.01`|
|0.25       |`r foundation_25_p`  |`r foundation_25_p<0.01`|`r lotshape_25_p`  |`r lotshape_25_p<0.01`|
|0.50       |`r foundation_50_p`  |`r foundation_50_p<0.01`|`r lotshape_50_p`  |`r lotshape_50_p<0.01`|
|0.80       |`r foundation_80_p`  |`r foundation_80_p<0.01`|`r lotshape_80_p`  |`r lotshape_80_p<0.01`|
|0.95       |`r foundation_95_p`  |`r foundation_95_p<0.01`|`r lotshape_95_p`  |`r lotshape_95_p<0.01`|


```{r, Warning=FALSE}
qrs_summary <- summary(qrs, se = "iid")
#tau: 0.1
q10_sig <- qrs_summary[11][[1]]$coefficients[,4][0:4]
#tau: 0.25
q25_sig <- qrs_summary[26][[1]]$coefficients[,4][0:4]
#tau: 0.5
q50_sig <- qrs_summary[51][[1]]$coefficients[,4][0:4]
#tau: 0.75
q75_sig <- qrs_summary[76][[1]]$coefficients[,4][0:4]
#tau: 0.9
q90_sig <- qrs_summary[91][[1]]$coefficients[,4][0:4]
```

Alpha=0.01

|Quantile   |GrLivArea p-value| significant?    | TotRmsAbvGrd p-value| significant?  | LotArea p-value| significant?   |
|----------:|----------------:|----------------:|--------------------:|--------------:|---------------:|------------------:|
|0.15       |`r q10_sig[2]`  |`r q10_sig[2]<0.01`|`r q10_sig[4]`  |`r q10_sig[4]<0.01`|`r q10_sig[3]`  |`r q10_sig[3]<0.01`|
|0.25       |`r q25_sig[2]`  |`r q25_sig[2]<0.01`|`r q25_sig[4]`  |`r q25_sig[4]<0.01`|`r q25_sig[3]`  |`r q25_sig[3]<0.01`|
|0.50       |`r q50_sig[2]`  |`r q50_sig[2]<0.01`|`r q50_sig[4]`  |`r q50_sig[4]<0.01`|`r q50_sig[3]`  |`r q50_sig[3]<0.01`|
|0.75       |`r q75_sig[2]`  |`r q75_sig[2]<0.01`|`r q75_sig[4]`  |`r q75_sig[4]<0.01`|`r q75_sig[3]`  |`r q75_sig[3]<0.01`|
|0.90       |`r q90_sig[2]`  |`r q90_sig[2]<0.01`|`r q90_sig[4]`  |`r q90_sig[4]<0.01`|`r q90_sig[3]`  |`r q90_sig[3]<0.01`|

As demonstrated in the previous 2 tables, p-value of each variable changes with the changing the quantile regressions' quantile. It can even switch from significant to non-significant. That is the case with lot shape in the 0.95th quantile. It was significant in all previous quantiles except in the 95th quantile. The same case is for number of the total rooms above ground. It was significant across all quantiles but is insignificant for the 90th quantile On the other hand OLS assumes that the significance is constant throughout the whole data set.